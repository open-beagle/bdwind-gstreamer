package webrtc

import (
	"context"
	"fmt"
	"log"
	"sync"
	"sync/atomic"
	"time"
)

// ConcurrentMessageRouter å¹¶å‘æ¶ˆæ¯è·¯ç”±å™¨
type ConcurrentMessageRouter struct {
	// åŸºç¡€è·¯ç”±å™¨
	baseRouter *MessageRouter

	// å¹¶å‘æ§åˆ¶
	workerPool   *WorkerPool
	messageQueue chan *MessageTask

	// æ€§èƒ½ç›‘æ§
	performanceMonitor *PerformanceMonitor

	// é…ç½®
	config *ConcurrentRouterConfig

	// ç»Ÿè®¡
	stats *ConcurrentRoutingStats

	// æ§åˆ¶
	ctx     context.Context
	cancel  context.CancelFunc
	running int32

	mutex sync.RWMutex
}

// ConcurrentRouterConfig å¹¶å‘è·¯ç”±å™¨é…ç½®
type ConcurrentRouterConfig struct {
	// å·¥ä½œæ± é…ç½®
	WorkerCount      int           `json:"worker_count"`
	QueueSize        int           `json:"queue_size"`
	MaxQueueWaitTime time.Duration `json:"max_queue_wait_time"`

	// æ€§èƒ½ä¼˜åŒ–é…ç½®
	EnableBatching bool          `json:"enable_batching"`
	BatchSize      int           `json:"batch_size"`
	BatchTimeout   time.Duration `json:"batch_timeout"`

	// è´Ÿè½½å‡è¡¡é…ç½®
	LoadBalanceMode string `json:"load_balance_mode"` // "round_robin", "least_loaded", "hash"

	// è¶…æ—¶é…ç½®
	ProcessingTimeout time.Duration `json:"processing_timeout"`

	// ç›‘æ§é…ç½®
	EnableMetrics   bool          `json:"enable_metrics"`
	MetricsInterval time.Duration `json:"metrics_interval"`
}

// MessageTask æ¶ˆæ¯ä»»åŠ¡
type MessageTask struct {
	ID           string
	ClientID     string
	MessageBytes []byte
	SubmitTime   time.Time
	ResponseChan chan *MessageTaskResult
	Context      context.Context
	Priority     int
	Retries      int
	MaxRetries   int
}

// MessageTaskResult æ¶ˆæ¯ä»»åŠ¡ç»“æœ
type MessageTaskResult struct {
	Success        bool
	Result         *RouteResult
	Error          error
	ProcessingTime time.Duration
	WorkerID       int
}

// WorkerPool å·¥ä½œæ± 
type WorkerPool struct {
	workers      []*MessageWorker
	workerCount  int
	nextWorker   int64
	loadBalancer LoadBalancer

	// ç»Ÿè®¡
	totalTasks     int64
	completedTasks int64
	failedTasks    int64

	mutex sync.RWMutex
}

// MessageWorker æ¶ˆæ¯å·¥ä½œå™¨
type MessageWorker struct {
	ID       int
	router   *MessageRouter
	taskChan chan *MessageTask

	// ç»Ÿè®¡
	processedTasks int64
	failedTasks    int64
	totalTime      time.Duration
	isIdle         int32

	// æ§åˆ¶
	ctx    context.Context
	cancel context.CancelFunc

	mutex sync.RWMutex
}

// LoadBalancer è´Ÿè½½å‡è¡¡å™¨æ¥å£
type LoadBalancer interface {
	SelectWorker(workers []*MessageWorker, task *MessageTask) *MessageWorker
}

// RoundRobinBalancer è½®è¯¢è´Ÿè½½å‡è¡¡å™¨
type RoundRobinBalancer struct {
	counter int64
}

// LeastLoadedBalancer æœ€å°‘è´Ÿè½½å‡è¡¡å™¨
type LeastLoadedBalancer struct{}

// HashBalancer å“ˆå¸Œè´Ÿè½½å‡è¡¡å™¨
type HashBalancer struct{}

// ConcurrentRoutingStats å¹¶å‘è·¯ç”±ç»Ÿè®¡
type ConcurrentRoutingStats struct {
	// ä»»åŠ¡ç»Ÿè®¡
	TotalTasks     int64 `json:"total_tasks"`
	CompletedTasks int64 `json:"completed_tasks"`
	FailedTasks    int64 `json:"failed_tasks"`
	QueuedTasks    int64 `json:"queued_tasks"`

	// æ€§èƒ½ç»Ÿè®¡
	AverageQueueTime   time.Duration `json:"average_queue_time"`
	AverageProcessTime time.Duration `json:"average_process_time"`
	ThroughputPerSec   float64       `json:"throughput_per_sec"`

	// å·¥ä½œå™¨ç»Ÿè®¡
	ActiveWorkers     int     `json:"active_workers"`
	IdleWorkers       int     `json:"idle_workers"`
	WorkerUtilization float64 `json:"worker_utilization"`

	// é˜Ÿåˆ—ç»Ÿè®¡
	QueueDepth     int   `json:"queue_depth"`
	MaxQueueDepth  int   `json:"max_queue_depth"`
	QueueOverflows int64 `json:"queue_overflows"`

	mutex sync.RWMutex
}

// DefaultConcurrentRouterConfig é»˜è®¤å¹¶å‘è·¯ç”±å™¨é…ç½®
func DefaultConcurrentRouterConfig() *ConcurrentRouterConfig {
	return &ConcurrentRouterConfig{
		WorkerCount:       10,
		QueueSize:         1000,
		MaxQueueWaitTime:  5 * time.Second,
		EnableBatching:    false,
		BatchSize:         10,
		BatchTimeout:      100 * time.Millisecond,
		LoadBalanceMode:   "least_loaded",
		ProcessingTimeout: 30 * time.Second,
		EnableMetrics:     true,
		MetricsInterval:   10 * time.Second,
	}
}

// NewConcurrentMessageRouter åˆ›å»ºå¹¶å‘æ¶ˆæ¯è·¯ç”±å™¨
func NewConcurrentMessageRouter(baseRouter *MessageRouter, config *ConcurrentRouterConfig, performanceMonitor *PerformanceMonitor) *ConcurrentMessageRouter {
	if config == nil {
		config = DefaultConcurrentRouterConfig()
	}

	ctx, cancel := context.WithCancel(context.Background())

	router := &ConcurrentMessageRouter{
		baseRouter:         baseRouter,
		messageQueue:       make(chan *MessageTask, config.QueueSize),
		performanceMonitor: performanceMonitor,
		config:             config,
		stats:              &ConcurrentRoutingStats{},
		ctx:                ctx,
		cancel:             cancel,
	}

	// åˆ›å»ºå·¥ä½œæ± 
	router.workerPool = router.createWorkerPool()

	return router
}

// createWorkerPool åˆ›å»ºå·¥ä½œæ± 
func (cmr *ConcurrentMessageRouter) createWorkerPool() *WorkerPool {
	var loadBalancer LoadBalancer

	switch cmr.config.LoadBalanceMode {
	case "round_robin":
		loadBalancer = &RoundRobinBalancer{}
	case "hash":
		loadBalancer = &HashBalancer{}
	default:
		loadBalancer = &LeastLoadedBalancer{}
	}

	pool := &WorkerPool{
		workers:      make([]*MessageWorker, cmr.config.WorkerCount),
		workerCount:  cmr.config.WorkerCount,
		loadBalancer: loadBalancer,
	}

	// åˆ›å»ºå·¥ä½œå™¨
	for i := 0; i < cmr.config.WorkerCount; i++ {
		worker := cmr.createWorker(i)
		pool.workers[i] = worker
	}

	return pool
}

// createWorker åˆ›å»ºå·¥ä½œå™¨
func (cmr *ConcurrentMessageRouter) createWorker(id int) *MessageWorker {
	ctx, cancel := context.WithCancel(cmr.ctx)

	worker := &MessageWorker{
		ID:       id,
		router:   cmr.baseRouter,
		taskChan: make(chan *MessageTask, 10), // æ¯ä¸ªå·¥ä½œå™¨çš„å°ç¼“å†²åŒº
		ctx:      ctx,
		cancel:   cancel,
		isIdle:   1, // åˆå§‹çŠ¶æ€ä¸ºç©ºé—²
	}

	return worker
}

// Start å¯åŠ¨å¹¶å‘è·¯ç”±å™¨
func (cmr *ConcurrentMessageRouter) Start() error {
	if !atomic.CompareAndSwapInt32(&cmr.running, 0, 1) {
		return fmt.Errorf("concurrent router is already running")
	}

	log.Printf("ğŸš€ Starting concurrent message router with %d workers", cmr.config.WorkerCount)

	// å¯åŠ¨å·¥ä½œå™¨
	for _, worker := range cmr.workerPool.workers {
		go worker.start()
	}

	// å¯åŠ¨ä»»åŠ¡åˆ†å‘å™¨
	go cmr.taskDispatcher()

	// å¯åŠ¨ç›‘æ§å™¨
	if cmr.config.EnableMetrics {
		go cmr.metricsCollector()
	}

	log.Printf("âœ… Concurrent message router started")
	return nil
}

// Stop åœæ­¢å¹¶å‘è·¯ç”±å™¨
func (cmr *ConcurrentMessageRouter) Stop() error {
	if !atomic.CompareAndSwapInt32(&cmr.running, 1, 0) {
		return fmt.Errorf("concurrent router is not running")
	}

	log.Printf("ğŸ›‘ Stopping concurrent message router...")

	// åœæ­¢æ¥æ”¶æ–°ä»»åŠ¡
	close(cmr.messageQueue)

	// åœæ­¢æ‰€æœ‰å·¥ä½œå™¨
	for _, worker := range cmr.workerPool.workers {
		worker.stop()
	}

	// å–æ¶ˆä¸Šä¸‹æ–‡
	cmr.cancel()

	log.Printf("âœ… Concurrent message router stopped")
	return nil
}

// RouteMessage è·¯ç”±æ¶ˆæ¯ï¼ˆå¹¶å‘ç‰ˆæœ¬ï¼‰
func (cmr *ConcurrentMessageRouter) RouteMessage(messageBytes []byte, clientID string) (*RouteResult, error) {
	if atomic.LoadInt32(&cmr.running) == 0 {
		return nil, fmt.Errorf("concurrent router is not running")
	}

	// åˆ›å»ºä»»åŠ¡
	task := &MessageTask{
		ID:           fmt.Sprintf("task_%d_%s", time.Now().UnixNano(), clientID),
		ClientID:     clientID,
		MessageBytes: messageBytes,
		SubmitTime:   time.Now(),
		ResponseChan: make(chan *MessageTaskResult, 1),
		Context:      context.WithValue(context.Background(), "client_id", clientID),
		Priority:     0,
		MaxRetries:   3,
	}

	// æäº¤ä»»åŠ¡åˆ°é˜Ÿåˆ—
	select {
	case cmr.messageQueue <- task:
		atomic.AddInt64(&cmr.stats.TotalTasks, 1)
		atomic.AddInt64(&cmr.stats.QueuedTasks, 1)
	case <-time.After(cmr.config.MaxQueueWaitTime):
		atomic.AddInt64(&cmr.stats.QueueOverflows, 1)
		return nil, fmt.Errorf("message queue is full, timeout after %v", cmr.config.MaxQueueWaitTime)
	}

	// ç­‰å¾…ç»“æœ
	select {
	case result := <-task.ResponseChan:
		atomic.AddInt64(&cmr.stats.QueuedTasks, -1)

		if result.Success {
			atomic.AddInt64(&cmr.stats.CompletedTasks, 1)

			// è®°å½•æ€§èƒ½æŒ‡æ ‡
			if cmr.performanceMonitor != nil {
				queueTime := result.ProcessingTime // è¿™é‡Œç®€åŒ–äº†ï¼Œå®é™…åº”è¯¥åˆ†åˆ«è®°å½•é˜Ÿåˆ—æ—¶é—´å’Œå¤„ç†æ—¶é—´
				cmr.performanceMonitor.RecordRoutingStats("concurrent", queueTime, true)
			}

			return result.Result, nil
		} else {
			atomic.AddInt64(&cmr.stats.FailedTasks, 1)

			// è®°å½•å¤±è´¥æŒ‡æ ‡
			if cmr.performanceMonitor != nil {
				cmr.performanceMonitor.RecordRoutingStats("concurrent", result.ProcessingTime, false)
			}

			return nil, result.Error
		}

	case <-time.After(cmr.config.ProcessingTimeout):
		atomic.AddInt64(&cmr.stats.QueuedTasks, -1)
		atomic.AddInt64(&cmr.stats.FailedTasks, 1)
		return nil, fmt.Errorf("message processing timeout after %v", cmr.config.ProcessingTimeout)
	}
}

// taskDispatcher ä»»åŠ¡åˆ†å‘å™¨
func (cmr *ConcurrentMessageRouter) taskDispatcher() {
	log.Printf("ğŸ“¡ Task dispatcher started")

	for {
		select {
		case task, ok := <-cmr.messageQueue:
			if !ok {
				log.Printf("ğŸ“¡ Task dispatcher stopping - message queue closed")
				return
			}

			// é€‰æ‹©å·¥ä½œå™¨
			worker := cmr.workerPool.loadBalancer.SelectWorker(cmr.workerPool.workers, task)
			if worker == nil {
				// æ‰€æœ‰å·¥ä½œå™¨éƒ½å¿™ï¼Œä½¿ç”¨è½®è¯¢é€‰æ‹©
				workerIndex := atomic.AddInt64(&cmr.workerPool.nextWorker, 1) % int64(cmr.workerPool.workerCount)
				worker = cmr.workerPool.workers[workerIndex]
			}

			// åˆ†å‘ä»»åŠ¡åˆ°å·¥ä½œå™¨
			select {
			case worker.taskChan <- task:
				// ä»»åŠ¡æˆåŠŸåˆ†å‘
			case <-time.After(100 * time.Millisecond):
				// å·¥ä½œå™¨å¿™ï¼Œå‘é€å¤±è´¥å“åº”
				task.ResponseChan <- &MessageTaskResult{
					Success:        false,
					Error:          fmt.Errorf("worker %d is busy", worker.ID),
					ProcessingTime: time.Since(task.SubmitTime),
					WorkerID:       worker.ID,
				}
			}

		case <-cmr.ctx.Done():
			log.Printf("ğŸ“¡ Task dispatcher stopping - context cancelled")
			return
		}
	}
}

// metricsCollector æŒ‡æ ‡æ”¶é›†å™¨
func (cmr *ConcurrentMessageRouter) metricsCollector() {
	ticker := time.NewTicker(cmr.config.MetricsInterval)
	defer ticker.Stop()

	log.Printf("ğŸ“Š Metrics collector started")

	for {
		select {
		case <-ticker.C:
			cmr.collectMetrics()
		case <-cmr.ctx.Done():
			log.Printf("ğŸ“Š Metrics collector stopping")
			return
		}
	}
}

// collectMetrics æ”¶é›†æŒ‡æ ‡
func (cmr *ConcurrentMessageRouter) collectMetrics() {
	cmr.stats.mutex.Lock()
	defer cmr.stats.mutex.Unlock()

	// æ›´æ–°é˜Ÿåˆ—æ·±åº¦
	cmr.stats.QueueDepth = len(cmr.messageQueue)
	if cmr.stats.QueueDepth > cmr.stats.MaxQueueDepth {
		cmr.stats.MaxQueueDepth = cmr.stats.QueueDepth
	}

	// ç»Ÿè®¡å·¥ä½œå™¨çŠ¶æ€
	activeWorkers := 0
	idleWorkers := 0

	for _, worker := range cmr.workerPool.workers {
		if atomic.LoadInt32(&worker.isIdle) == 0 {
			activeWorkers++
		} else {
			idleWorkers++
		}
	}

	cmr.stats.ActiveWorkers = activeWorkers
	cmr.stats.IdleWorkers = idleWorkers
	cmr.stats.WorkerUtilization = float64(activeWorkers) / float64(cmr.config.WorkerCount) * 100

	// è®¡ç®—ååé‡
	if cmr.stats.CompletedTasks > 0 {
		duration := time.Since(time.Now().Add(-cmr.config.MetricsInterval))
		cmr.stats.ThroughputPerSec = float64(cmr.stats.CompletedTasks) / duration.Seconds()
	}

	// è®°å½•è¯¦ç»†æŒ‡æ ‡
	log.Printf("ğŸ“Š Concurrent Router Metrics: Queue=%d, Active=%d/%d, Throughput=%.2f/s, Utilization=%.1f%%",
		cmr.stats.QueueDepth, activeWorkers, cmr.config.WorkerCount,
		cmr.stats.ThroughputPerSec, cmr.stats.WorkerUtilization)
}

// start å¯åŠ¨å·¥ä½œå™¨
func (mw *MessageWorker) start() {
	log.Printf("ğŸ‘· Worker %d started", mw.ID)

	for {
		select {
		case task, ok := <-mw.taskChan:
			if !ok {
				log.Printf("ğŸ‘· Worker %d stopping - task channel closed", mw.ID)
				return
			}

			mw.processTask(task)

		case <-mw.ctx.Done():
			log.Printf("ğŸ‘· Worker %d stopping - context cancelled", mw.ID)
			return
		}
	}
}

// stop åœæ­¢å·¥ä½œå™¨
func (mw *MessageWorker) stop() {
	log.Printf("ğŸ‘· Worker %d stopping...", mw.ID)
	close(mw.taskChan)
	mw.cancel()
}

// processTask å¤„ç†ä»»åŠ¡
func (mw *MessageWorker) processTask(task *MessageTask) {
	startTime := time.Now()
	atomic.StoreInt32(&mw.isIdle, 0)       // æ ‡è®°ä¸ºå¿™ç¢Œ
	defer atomic.StoreInt32(&mw.isIdle, 1) // æ ‡è®°ä¸ºç©ºé—²

	mw.mutex.Lock()
	mw.processedTasks++
	mw.mutex.Unlock()

	// å¤„ç†æ¶ˆæ¯
	result, err := mw.router.RouteMessage(task.MessageBytes, task.ClientID)
	processingTime := time.Since(startTime)

	// æ›´æ–°å·¥ä½œå™¨ç»Ÿè®¡
	mw.mutex.Lock()
	mw.totalTime += processingTime
	if err != nil {
		mw.failedTasks++
	}
	mw.mutex.Unlock()

	// å‘é€ç»“æœ
	taskResult := &MessageTaskResult{
		Success:        err == nil,
		Result:         result,
		Error:          err,
		ProcessingTime: processingTime,
		WorkerID:       mw.ID,
	}

	select {
	case task.ResponseChan <- taskResult:
		// ç»“æœå‘é€æˆåŠŸ
	case <-time.After(1 * time.Second):
		// ç»“æœå‘é€è¶…æ—¶ï¼Œè®°å½•é”™è¯¯
		log.Printf("âŒ Worker %d failed to send result for task %s", mw.ID, task.ID)
	}
}

// GetStats è·å–å·¥ä½œå™¨ç»Ÿè®¡
func (mw *MessageWorker) GetStats() map[string]interface{} {
	mw.mutex.RLock()
	defer mw.mutex.RUnlock()

	var avgTime time.Duration
	if mw.processedTasks > 0 {
		avgTime = mw.totalTime / time.Duration(mw.processedTasks)
	}

	return map[string]interface{}{
		"worker_id":       mw.ID,
		"processed_tasks": mw.processedTasks,
		"failed_tasks":    mw.failedTasks,
		"average_time":    avgTime,
		"is_idle":         atomic.LoadInt32(&mw.isIdle) == 1,
	}
}

// SelectWorker è½®è¯¢é€‰æ‹©å·¥ä½œå™¨
func (rrb *RoundRobinBalancer) SelectWorker(workers []*MessageWorker, task *MessageTask) *MessageWorker {
	if len(workers) == 0 {
		return nil
	}

	index := atomic.AddInt64(&rrb.counter, 1) % int64(len(workers))
	return workers[index]
}

// SelectWorker é€‰æ‹©è´Ÿè½½æœ€å°‘çš„å·¥ä½œå™¨
func (llb *LeastLoadedBalancer) SelectWorker(workers []*MessageWorker, task *MessageTask) *MessageWorker {
	if len(workers) == 0 {
		return nil
	}

	var bestWorker *MessageWorker
	var minLoad int64 = -1

	for _, worker := range workers {
		// ä¼˜å…ˆé€‰æ‹©ç©ºé—²çš„å·¥ä½œå™¨
		if atomic.LoadInt32(&worker.isIdle) == 1 {
			return worker
		}

		// é€‰æ‹©å¤„ç†ä»»åŠ¡æœ€å°‘çš„å·¥ä½œå™¨
		worker.mutex.RLock()
		load := worker.processedTasks
		worker.mutex.RUnlock()

		if minLoad == -1 || load < minLoad {
			minLoad = load
			bestWorker = worker
		}
	}

	return bestWorker
}

// SelectWorker åŸºäºå“ˆå¸Œé€‰æ‹©å·¥ä½œå™¨
func (hb *HashBalancer) SelectWorker(workers []*MessageWorker, task *MessageTask) *MessageWorker {
	if len(workers) == 0 {
		return nil
	}

	// ä½¿ç”¨å®¢æˆ·ç«¯IDçš„å“ˆå¸Œå€¼é€‰æ‹©å·¥ä½œå™¨
	hash := 0
	for _, b := range []byte(task.ClientID) {
		hash = hash*31 + int(b)
	}

	index := hash % len(workers)
	if index < 0 {
		index = -index
	}

	return workers[index]
}

// GetStats è·å–å¹¶å‘è·¯ç”±ç»Ÿè®¡
func (cmr *ConcurrentMessageRouter) GetStats() *ConcurrentRoutingStats {
	cmr.stats.mutex.RLock()
	defer cmr.stats.mutex.RUnlock()

	stats := *cmr.stats
	return &stats
}

// GetWorkerStats è·å–æ‰€æœ‰å·¥ä½œå™¨ç»Ÿè®¡
func (cmr *ConcurrentMessageRouter) GetWorkerStats() []map[string]interface{} {
	stats := make([]map[string]interface{}, len(cmr.workerPool.workers))

	for i, worker := range cmr.workerPool.workers {
		stats[i] = worker.GetStats()
	}

	return stats
}

// GetDetailedStats è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
func (cmr *ConcurrentMessageRouter) GetDetailedStats() map[string]interface{} {
	return map[string]interface{}{
		"config":        cmr.config,
		"routing_stats": cmr.GetStats(),
		"worker_stats":  cmr.GetWorkerStats(),
		"queue_size":    len(cmr.messageQueue),
		"queue_cap":     cap(cmr.messageQueue),
		"running":       atomic.LoadInt32(&cmr.running) == 1,
	}
}
